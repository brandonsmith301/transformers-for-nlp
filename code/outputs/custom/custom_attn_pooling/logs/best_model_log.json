{
  "model_type": "custom",
  "config": {
    "seed": 330,
    "model": {
      "pretrained_model_path": "weights/pretrained",
      "max_seq_len": 512,
      "vocab_size": 30522,
      "n_layer": 12,
      "n_head": 12,
      "n_embd": 768,
      "dropout": 0.1,
      "bias": true,
      "num_classes": 2,
      "mlm_probability": 0.15,
      "rotary_dim": 64,
      "rope_theta": 10000.0,
      "original_seq_len": 512,
      "rope_factor": 1.0,
      "beta_fast": 32.0,
      "beta_slow": 1.0,
      "pad_token_id": 0,
      "mask_token_id": 103,
      "contrastive_weight": 0.1,
      "pooling_type": "AttentionPooling",
      "lstm_pooling": {
        "hidden_size": 768,
        "dropout_rate": 0.1,
        "bidirectional": true
      },
      "gru_pooling": {
        "hidden_size": 768,
        "dropout_rate": 0.1,
        "bidirectional": true
      },
      "weighted_pooling": {
        "layer_start": 9,
        "layer_weights": null
      },
      "concat_pooling": {
        "n_layers": 4
      },
      "attention_pooling": {
        "hiddendim_fc": 768,
        "dropout": 0.1
      },
      "wk_pooling": {
        "layer_start": 9,
        "context_window_size": 2
      }
    },
    "dataset": {
      "tokenizer_path": "bert-base-uncased",
      "use_fast": true,
      "padding_side": "right",
      "truncation_side": "right",
      "max_length": 512
    },
    "training": {
      "learning_rate": 3e-05,
      "betas": [
        0.9,
        0.999
      ],
      "weight_decay": 0.01,
      "batch_size": 4,
      "num_epochs": 10,
      "gradient_accumulation_steps": 4,
      "max_grad_norm": 1.0,
      "use_mask_aug": false,
      "mask_aug_prob": 0.15,
      "warmup_pct": 0.05,
      "save_trigger": 0.0,
      "eval_frequency": 100,
      "patience": 10
    },
    "outputs": {
      "model_dir": "outputs/custom/custom_attn_pooling"
    }
  },
  "training_history": [
    {
      "epoch": 1,
      "step": 399,
      "total_step": 100,
      "time_elapsed": "00:59",
      "accuracy": 0.6364,
      "scores": {
        "accuracy": 0.6364
      },
      "learning_rate": 3.841229193341869e-06,
      "loss": 0.682781982421875
    },
    {
      "epoch": 1,
      "step": 799,
      "total_step": 200,
      "time_elapsed": "01:58",
      "accuracy": 0.7094,
      "scores": {
        "accuracy": 0.7094
      },
      "learning_rate": 7.682458386683739e-06,
      "loss": 0.6629731559753418
    },
    {
      "epoch": 1,
      "step": 1199,
      "total_step": 300,
      "time_elapsed": "02:57",
      "accuracy": 0.723,
      "scores": {
        "accuracy": 0.723
      },
      "learning_rate": 1.152368758002561e-05,
      "loss": 0.6652320130666097
    },
    {
      "epoch": 1,
      "step": 1599,
      "total_step": 400,
      "time_elapsed": "03:55",
      "accuracy": 0.6794,
      "scores": {
        "accuracy": 0.6794
      },
      "learning_rate": 1.5364916773367477e-05,
      "loss": 0.6543965636193753
    },
    {
      "epoch": 1,
      "step": 1999,
      "total_step": 500,
      "time_elapsed": "04:53",
      "accuracy": 0.7744,
      "scores": {
        "accuracy": 0.7744
      },
      "learning_rate": 1.9206145966709347e-05,
      "loss": 0.6365446108579635
    },
    {
      "epoch": 1,
      "step": 2399,
      "total_step": 600,
      "time_elapsed": "05:52",
      "accuracy": 0.7844,
      "scores": {
        "accuracy": 0.7844
      },
      "learning_rate": 2.304737516005122e-05,
      "loss": 0.6285731640458107
    },
    {
      "epoch": 1,
      "step": 2799,
      "total_step": 700,
      "time_elapsed": "06:51",
      "accuracy": 0.7358,
      "scores": {
        "accuracy": 0.7358
      },
      "learning_rate": 2.6888604353393085e-05,
      "loss": 0.6111169535773141
    },
    {
      "epoch": 1,
      "step": 3199,
      "total_step": 800,
      "time_elapsed": "07:50",
      "accuracy": 0.8154,
      "scores": {
        "accuracy": 0.8154
      },
      "learning_rate": 2.9999878644809757e-05,
      "loss": 0.604711895659566
    },
    {
      "epoch": 1,
      "step": 3599,
      "total_step": 900,
      "time_elapsed": "08:48",
      "accuracy": 0.7294,
      "scores": {
        "accuracy": 0.7294
      },
      "learning_rate": 2.9995239827507286e-05,
      "loss": 0.5969223019149569
    },
    {
      "epoch": 1,
      "step": 3999,
      "total_step": 1000,
      "time_elapsed": "09:47",
      "accuracy": 0.7903,
      "scores": {
        "accuracy": 0.7903
      },
      "learning_rate": 2.9983880106544152e-05,
      "loss": 0.5994753728955984
    },
    {
      "epoch": 1,
      "step": 4399,
      "total_step": 1100,
      "time_elapsed": "10:46",
      "accuracy": 0.8416,
      "scores": {
        "accuracy": 0.8416
      },
      "learning_rate": 2.996580457337544e-05,
      "loss": 0.5893142142079093
    },
    {
      "epoch": 1,
      "step": 4799,
      "total_step": 1200,
      "time_elapsed": "11:44",
      "accuracy": 0.8483,
      "scores": {
        "accuracy": 0.8483
      },
      "learning_rate": 2.9941021329499924e-05,
      "loss": 0.5823212006253501
    },
    {
      "epoch": 1,
      "step": 5199,
      "total_step": 1300,
      "time_elapsed": "12:43",
      "accuracy": 0.8291,
      "scores": {
        "accuracy": 0.8291
      },
      "learning_rate": 2.9909541482828937e-05,
      "loss": 0.5741741417176448
    },
    {
      "epoch": 1,
      "step": 5599,
      "total_step": 1400,
      "time_elapsed": "13:42",
      "accuracy": 0.8184,
      "scores": {
        "accuracy": 0.8184
      },
      "learning_rate": 2.987137914270779e-05,
      "loss": 0.5679443556762167
    },
    {
      "epoch": 1,
      "step": 5999,
      "total_step": 1500,
      "time_elapsed": "14:41",
      "accuracy": 0.7952,
      "scores": {
        "accuracy": 0.7952
      },
      "learning_rate": 2.9826551413591927e-05,
      "loss": 0.5589254902005195
    },
    {
      "epoch": 2,
      "step": 147,
      "total_step": 1600,
      "time_elapsed": "15:40",
      "accuracy": 0.8538,
      "scores": {
        "accuracy": 0.8538
      },
      "learning_rate": 2.9775078387380648e-05,
      "loss": 0.3755730787241781
    },
    {
      "epoch": 2,
      "step": 547,
      "total_step": 1700,
      "time_elapsed": "16:38",
      "accuracy": 0.8616,
      "scores": {
        "accuracy": 0.8616
      },
      "learning_rate": 2.9716983134411898e-05,
      "loss": 0.3562988465393547
    },
    {
      "epoch": 2,
      "step": 947,
      "total_step": 1800,
      "time_elapsed": "17:38",
      "accuracy": 0.8584,
      "scores": {
        "accuracy": 0.8584
      },
      "learning_rate": 2.965229169312206e-05,
      "loss": 0.3307647176621332
    },
    {
      "epoch": 2,
      "step": 1347,
      "total_step": 1900,
      "time_elapsed": "18:36",
      "accuracy": 0.8406,
      "scores": {
        "accuracy": 0.8406
      },
      "learning_rate": 2.958103305837548e-05,
      "loss": 0.32964868224516114
    },
    {
      "epoch": 2,
      "step": 1747,
      "total_step": 2000,
      "time_elapsed": "19:34",
      "accuracy": 0.8525,
      "scores": {
        "accuracy": 0.8525
      },
      "learning_rate": 2.950323916846888e-05,
      "loss": 0.3322281210728041
    },
    {
      "epoch": 2,
      "step": 2147,
      "total_step": 2100,
      "time_elapsed": "20:32",
      "accuracy": 0.8165,
      "scores": {
        "accuracy": 0.8165
      },
      "learning_rate": 2.941894489081655e-05,
      "loss": 0.3275517018397427
    },
    {
      "epoch": 2,
      "step": 2547,
      "total_step": 2200,
      "time_elapsed": "21:31",
      "accuracy": 0.8618,
      "scores": {
        "accuracy": 0.8618
      },
      "learning_rate": 2.9328188006322693e-05,
      "loss": 0.33422343132306864
    },
    {
      "epoch": 2,
      "step": 2947,
      "total_step": 2300,
      "time_elapsed": "22:30",
      "accuracy": 0.8662,
      "scores": {
        "accuracy": 0.8662
      },
      "learning_rate": 2.923100919244789e-05,
      "loss": 0.3331434650490695
    },
    {
      "epoch": 2,
      "step": 3347,
      "total_step": 2400,
      "time_elapsed": "23:29",
      "accuracy": 0.8634,
      "scores": {
        "accuracy": 0.8634
      },
      "learning_rate": 2.9127452004977417e-05,
      "loss": 0.3333904949086969
    },
    {
      "epoch": 2,
      "step": 3747,
      "total_step": 2500,
      "time_elapsed": "24:28",
      "accuracy": 0.8656,
      "scores": {
        "accuracy": 0.8656
      },
      "learning_rate": 2.9017562858499392e-05,
      "loss": 0.3351681627961335
    },
    {
      "epoch": 2,
      "step": 4147,
      "total_step": 2600,
      "time_elapsed": "25:27",
      "accuracy": 0.868,
      "scores": {
        "accuracy": 0.868
      },
      "learning_rate": 2.890139100560166e-05,
      "loss": 0.3371499800909106
    },
    {
      "epoch": 2,
      "step": 4547,
      "total_step": 2700,
      "time_elapsed": "26:25",
      "accuracy": 0.8627,
      "scores": {
        "accuracy": 0.8627
      },
      "learning_rate": 2.8778988514796644e-05,
      "loss": 0.3328635291234904
    },
    {
      "epoch": 2,
      "step": 4947,
      "total_step": 2800,
      "time_elapsed": "27:24",
      "accuracy": 0.8655,
      "scores": {
        "accuracy": 0.8655
      },
      "learning_rate": 2.865041024718414e-05,
      "loss": 0.330183508487459
    },
    {
      "epoch": 2,
      "step": 5347,
      "total_step": 2900,
      "time_elapsed": "28:23",
      "accuracy": 0.8684,
      "scores": {
        "accuracy": 0.8684
      },
      "learning_rate": 2.8515713831862415e-05,
      "loss": 0.3283185679228696
    },
    {
      "epoch": 2,
      "step": 5747,
      "total_step": 3000,
      "time_elapsed": "29:22",
      "accuracy": 0.81,
      "scores": {
        "accuracy": 0.81
      },
      "learning_rate": 2.837495964009869e-05,
      "loss": 0.32443216253816043
    },
    {
      "epoch": 2,
      "step": 6147,
      "total_step": 3100,
      "time_elapsed": "30:20",
      "accuracy": 0.863,
      "scores": {
        "accuracy": 0.863
      },
      "learning_rate": 2.8228210758270622e-05,
      "loss": 0.3270161402452357
    },
    {
      "epoch": 3,
      "step": 295,
      "total_step": 3200,
      "time_elapsed": "31:20",
      "accuracy": 0.8716,
      "scores": {
        "accuracy": 0.8716
      },
      "learning_rate": 2.80755329595908e-05,
      "loss": 0.2216134515364428
    }
  ],
  "best_score": 0.8716,
  "best_epoch": 3,
  "best_step": 3200,
  "training_time": "31:20",
  "best_metrics": {
    "accuracy_at_best": 0.8716
  }
}